{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "UyNc81DoHzOU"
            },
            "source": [
                "# Generate Counterfactuals by Distance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "EJjH3xcvHzOY"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from src.datasets import IMDBDataset\n",
                "from src.models import AnalysisModels\n",
                "from src.analyzers.svm import SVMDistanceAnalyzer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "C0A-GJtyHzOZ",
                "outputId": "afb57bcf-3879-4f4d-c245-0783c8c41747"
            },
            "outputs": [],
            "source": [
                "ds = IMDBDataset(config_path=\"./configs/datasets/imdb.yaml\", root=\"datasets/imdb\")\n",
                "models = AnalysisModels(config_path=\"./configs/models/analysis-models.yaml\", root=\"models/analysis-models\")\n",
                "model = models.svm.model\n",
                "analyzer = SVMDistanceAnalyzer(model, ds, \"datasets/imdb/svm_buffer.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "i7HzsoGOHzOa",
                "outputId": "b99d72cc-64b4-4bb7-c373-ed48fcc9e406"
            },
            "outputs": [],
            "source": [
                "import json\n",
                "print(json.dumps(analyzer.get_counterfactual_examples([\n",
                "    \"I would like to remind that this movie was advertised as a real-life story. But what is this?. A waste of my good money!\",\n",
                "    \"This is the best movie I had watched so far. The marvelous CGI and super story line successfully kept the eyes of the audience fixed.\"\n",
                "]), indent=4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rYvdVcodHzOb"
            },
            "source": [
                "# Generate Counterfactuals by Opposite Neighbourhood"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XH3KTuE_HzOb"
            },
            "source": [
                "## SVM Theory\n",
                "What SVM does\n",
                "$$\n",
                "\\boxed{\"prompt\"}\\rightarrow\\boxed{Vector_{TFIDF}\\ (i.e., x)}\\rightarrow\\boxed{Vector_{SVM}\\ (i.e., \\phi(x))}\\\\\n",
                "x\\in R^m,\\ \\phi(x)\\in R^n.\n",
                "$$\n",
                "Note that here $m$ is the number of dimensions in the vector space of the TFIDF Vectorizer and $n$ is the number of dimensions in the vector space learnt by the SVM. $\\phi(x)$ is known as the kernel function. Hence, the vector space learnt by the SVM is commonly known as the **output vector space of the kernel function**.\n",
                "\n",
                "Once the SVM learns the vector space of $\\phi(x)$, it finds the best hyperplane that satisfies $w^T.\\phi(x)+b=0$. Note that $w$ are the coefficients with size $n$. This equation can be expanded as $w_1\\phi_1(x)+w_2\\phi_2(x)+w_3\\phi_3(x)...+w_n\\phi_n(x)+b$\n",
                "\n",
                "## Our method\n",
                "We will be using the following method to generate counter factuals for a given $prompt$.\n",
                "1. Generate a set of contradictory prompts for the given prompt.\n",
                "2. Vectorize all the prompts using the TFIDF vetorizer into the vector space $X$.\n",
                "3. Project all the vectors into the SVM's kernel space $K$.\n",
                "4. Find the mirror point of the given prompt's TFIDF vector on the hyperplane of the SVM ($C$).\n",
                "5. Out of the vectors of the contradictory prompts, find the closest point to $C$. Then the prompt corresponding to this point will be returned\n",
                "\n",
                "### 1. Contradictory prompt generation\n",
                "\n",
                "We will generate contradictory prompts for a given prompt $prompt_0$ using a finetuned T5 model/ custom WordFlippingGenerator. These new prompts will be $[contradictory\\_prompt_i]$\n",
                "\n",
                "\n",
                "### 2. Vectorize into $X$\n",
                "$$\n",
                "\\boxed{\"prompt_0\"}\\rightarrow\\boxed{Vector_{TFIDF}\\ (i.e., x_0)}\n",
                "$$\n",
                "The $prompt_0$ will be mapped to $x_0$ from the TFIFT vectorizer. The $[contradictory\\_prompt_i]$ s will be mapped to $[x_{c,i}]$\n",
                "\n",
                "### 3. Project into $K$\n",
                "SVM is already learnt. i.e., we know the kernel function ($\\phi(.)$), coefficients ($w$), and the bias ($b$). Hence, we will project $x_0$ and $[x_{c,i}]$ into $K$\n",
                "\n",
                "$$\n",
                "\\boxed{Vector_{TFIDF}\\ (i.e., x_0)}\\rightarrow\\boxed{Vector_{SVM}\\ (i.e., \\phi(x_0)\\in K)}\n",
                "$$\n",
                "We will call this $\\phi(x_0)$ as $A$ for simplicity\n",
                "\n",
                "##### $\\phi(.)$ when the kernel is RBF\n",
                "Assume that a single TFIDF vector will have the size $n$ and the number of support vectors will be $m$. The RBF kernel is given by\n",
                "$$\n",
                "K( \\overrightarrow{x}, \\overrightarrow{l^m})=e^{-\\gamma{||\\overrightarrow{x}-\\overrightarrow{l^m}||}^2}\n",
                "$$\n",
                "Here $x$ is a vector in the TFIDF vector space with size $m$. $l^m$ is a collection of $m$ vectors (i.e., the support vectors) with each of size $n$.\n",
                "\n",
                "### 4. Find $A$'s mirror point ($C$)\n",
                "Once we have $\\phi(x_0)$ for the given prompt, we find its opposite projection on the hyperplane of the SVM characterised by $w$ and $b$. For simplicity, we'll call $\\phi(x_0)$ as $A$ and $hyperplane$ as $h$.\n",
                "$$\n",
                "hyperplane=h\\equiv(w_1, w_2,...w_n, b) \\\\\n",
                "\\phi(x_0)=A=(a_1,a_2,...a_n)\n",
                "$$\n",
                "Any line $l$ which is normal to the $h$ through $A$ will be given by the parametric equation\n",
                "$$\n",
                "l\\equiv A+tw=0\\\\\n",
                "l\\equiv (a_1+tw_1, a_2+tw_2,...,a_n+tw_n)\n",
                "$$\n",
                "Let $t$ take the value $t_0$ at the point $B$ that lies on this line and the hyperplane.\n",
                "$$\n",
                "B\\equiv (a_1+t_0w_1, a_2+t_0w_2,...,a_n+t_0w_n)\n",
                "$$\n",
                "Since this point would also satisfy the hyperplane,\n",
                "$$\n",
                "w^T.l_0+b=0 \\\\\n",
                "(w_1(a_1+t_0w_1), w_2(a_2+t_0w_2),...,w_n(a_n+t_0w_n))+b=0\\\\\n",
                "t_0=-\\frac{(b+w^T.A)}{||w||_2^2}\n",
                "$$\n",
                "The mirror point $C$ will exist where $t=2t_0$. Hence,\n",
                "$$\n",
                "C\\equiv (a_1+2t_0w_1, a_2+2t_0w_2,...,a_n+2t_0w_n)\n",
                "$$\n",
                "\n",
                "##### Example\n",
                "\n",
                "Reflection of point $A(3,1,2)$ on the hyperplane $x+2y+z=1$ (Note that here, $(3,1,2)=(a_1,a_2,a_3)$, $(1,2,1)=(w_1,w_2,w_3)$, and $-1=b$)\n",
                "1. Construct the line normal to the plane that intersects point $A(3,1,2)$:\n",
                "  $$\n",
                "  line (x,y,z)=(3,1,2)+t(1,2,1)\n",
                "  $$\n",
                "  (Any line normal to the plane $x+2y+z=c$ will move in the direction $(1,2,1)$)\n",
                "\n",
                "2. Find the point B on the normal line that intersects the plane:\n",
                "  $$\n",
                "  (3+t)+2(1+2t)+(2+t)=1\n",
                "  $$\n",
                "\n",
                "  Solving, we get $t=-1$. Hence the intersection point $B$ (on the plane) is at $(2,-1,1)$.\n",
                "\n",
                "3. Point $A$ is at $t=0$, and point $B$ is at $t=-1$, so the mirror image of $A$, say $\\hat{A}$ will be twice the distance, at $t=-2$:\n",
                "  $$\n",
                "  \\boxed{ \\hat{A} \\equiv (1,-3,0)}\n",
                "  $$\n",
                "\n",
                "### 5. Find the closest point to C and retreive the contradictory prompt\n",
                "Now that the mirror point and contradictory points are all in the kerrnel space, the distance to the contradictory points from the point $C$ will be found. The prompt will be selected as the one which yields the smallest distance to the point $C$.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "liq_5eWNHzOb",
                "outputId": "d05f17cc-1946-492b-daaf-92557bc717fc"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from src.models import AnalysisModels\n",
                "from src.datasets import IMDBDataset\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "models = AnalysisModels(\"./configs/models/analysis-models.yaml\", \"./models/analysis-models\")\n",
                "dataset = IMDBDataset(\"./configs/datasets/imdb.yaml\", \"./datasets/imdb/\")\n",
                "\n",
                "svc_rbf = models.svm.model\n",
                "x = dataset.x_test.toarray()\n",
                "p = np.random.randn(x.shape[1])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "55XDlY_MHzOc"
            },
            "source": [
                "### Linear kernel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "rNSyZMDVHzOe",
                "outputId": "5ab4ee92-a2d9-4d75-80bc-9bf41369b9b8"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Your code here (with the provided function)\n",
                "from sklearn.svm import SVC\n",
                "import numpy as np\n",
                "\n",
                "X_train = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n",
                "y_train = np.array([0, 0, 1, 1])\n",
                "\n",
                "svm = SVC(kernel='linear', degree=3)\n",
                "svm.fit(X_train, y_train)\n",
                "\n",
                "def get_mirror_point_linear(svm, qp):\n",
                "    w = svm.coef_[0]\n",
                "    b = svm.intercept_[0]\n",
                "    t = -(b+w.dot(qp))/(np.linalg.norm(w)**2)\n",
                "    mp = qp + 2*t*w\n",
                "    return mp\n",
                "\n",
                "query_point = np.array([13, 5])\n",
                "mirror_point = get_mirror_point_linear(svm, query_point)\n",
                "\n",
                "print(f\"Query point: {query_point}, Distance: {svm.decision_function([query_point])}\")\n",
                "print(f\"Mirror point: {mirror_point}, Distance: {svm.decision_function([mirror_point])}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "hwMPqhByHzOe"
            },
            "source": [
                "### Polynomial Kernel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "lvqutm_9HzOe",
                "outputId": "3425d936-793f-41b8-8822-cb9045319f7c"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Your code here (with the provided function)\n",
                "from sklearn.svm import SVC\n",
                "import numpy as np\n",
                "\n",
                "X_train = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n",
                "y_train = np.array([0, 0, 1, 1])\n",
                "\n",
                "# Linear kernel SVM\n",
                "svm_linear = SVC(kernel='linear', degree=3)\n",
                "svm_linear.fit(X_train, y_train)\n",
                "\n",
                "# Polynomial kernel SVM\n",
                "svm_poly = SVC(kernel='poly', degree=3)\n",
                "svm_poly.fit(X_train, y_train)\n",
                "\n",
                "def get_k_poly(svm, x):\n",
                "    svs = svm.support_vectors_\n",
                "    d = svm.degree\n",
                "    gamma = svm._gamma\n",
                "    print(svs.shape, x.shape)\n",
                "    k = (gamma * np.dot(svs, x.T) + 1) ** d\n",
                "    return k\n",
                "\n",
                "def distance_to_hyperplane(svm_model, point):\n",
                "    # Get the support vectors, coefficients, and bias from the trained SVM model\n",
                "    support_vectors = svm_model.support_vectors_\n",
                "    dual_coefficients = svm_model.dual_coef_[0]\n",
                "    bias = svm_model.intercept_\n",
                "\n",
                "    # Get the kernel coefficient and degree from the trained SVM model\n",
                "    gamma = svm_model._gamma\n",
                "    degree = svm_model.degree\n",
                "\n",
                "    # Compute the distance to the hyperplane\n",
                "    distance = 0.0\n",
                "    for i in range(len(support_vectors)):\n",
                "        # Calculate the polynomial kernel between the support vector and the given point\n",
                "        kernel_value = (gamma * np.dot(support_vectors[i], point) + 1) ** degree\n",
                "\n",
                "        # Update the distance using the support vector and kernel value\n",
                "        distance += dual_coefficients[i] * kernel_value\n",
                "\n",
                "    # Add the bias term to the distance\n",
                "    distance += bias\n",
                "\n",
                "    return distance\n",
                "\n",
                "p = np.array([\n",
                "    [-8,2],\n",
                "    [-3,3],\n",
                "    [-2,4],\n",
                "    [-1,5]\n",
                "])\n",
                "# svm_poly.decision_function(p), distance_to_hyperplane(svm_poly, p[0])\n",
                "get_k_poly(svm_poly, p).shape\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "KfOXK5toHzOf"
            },
            "source": [
                "### RBF Kernel Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "eHYR85aqHzOf"
            },
            "source": [
                "#### Implementation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "ijGzCIE_HzOf"
            },
            "source": [
                "##### Method 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mhZRjBr4HzOf"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "from sklearn.datasets import make_circles\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "X, y = make_circles(n_samples=500, noise=0.06, random_state=42)\n",
                "\n",
                "df = pd.DataFrame(dict(x1=X[:, 0], x2=X[:, 1], y=y))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "LzkSp168HzOf",
                "outputId": "3ef68dd3-8ff6-4078-d0df-6f3d7b763311"
            },
            "outputs": [],
            "source": [
                "colors = {0:'blue', 1:'yellow'}\n",
                "fig, ax = plt.subplots()\n",
                "grouped = df.groupby('y')\n",
                "for key, group in grouped:\n",
                "    group.plot(ax=ax, kind='scatter', x='x1', y='x2', label=key, color = colors[key])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "XoYE52mcHzOg"
            },
            "outputs": [],
            "source": [
                "def RBF(X, gamma):\n",
                "\n",
                "    # Free parameter gamma\n",
                "    if gamma == None:\n",
                "        gamma = 1.0/X.shape[1]\n",
                "\n",
                "    # RBF kernel Equation\n",
                "    K = np.exp(-gamma * np.sum((X - X[:,np.newaxis])**2, axis = -1))\n",
                "\n",
                "    return K"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "x30blrlKHzOg"
            },
            "outputs": [],
            "source": [
                "clf_rbf = SVC(kernel=\"rbf\")\n",
                "clf_rbf.fit(X, y)\n",
                "K = RBF(X, gamma=clf_rbf._gamma)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "GOzY_G2WHzOg",
                "outputId": "947e6722-de29-4745-db34-e893657e2738"
            },
            "outputs": [],
            "source": [
                "clf = SVC(kernel=\"linear\")\n",
                "\n",
                "clf.fit(K, y)\n",
                "\n",
                "pred = clf.predict(K)\n",
                "\n",
                "print(\"Accuracy: \",accuracy_score(pred, y))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Y5n0Ksg8HzOg"
            },
            "source": [
                "##### Method 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "1ycJT7iHHzOg",
                "outputId": "3145d339-be04-4014-db1a-e77d7df34e81"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "from sklearn.svm import SVC\n",
                "import numpy as np\n",
                "\n",
                "X_train = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n",
                "y_train = np.array([0, 0, 1, 1])\n",
                "\n",
                "svm = SVC(kernel='rbf', gamma='scale', degree=3)\n",
                "svm.fit(X_train, y_train)\n",
                "\n",
                "def get_distance_rbf(svm, qp):\n",
                "    # Calculate the distance from the query point to each support vector\n",
                "    sv = svm.support_vectors_\n",
                "    distances = np.linalg.norm(sv - qp, axis=1)\n",
                "\n",
                "    # Use the decision function to get the weight (distance) for each support vector\n",
                "    decision_values = svm.decision_function([qp])[0]\n",
                "    weights = np.exp(-svm._gamma * (distances ** 2)) * decision_values\n",
                "\n",
                "    # Calculate the weighted average of the support vectors to obtain the approximate mirror point\n",
                "    weighted_average = np.average(sv, axis=0, weights=weights)\n",
                "\n",
                "    return weighted_average\n",
                "\n",
                "query_point = np.array([1, 5])\n",
                "mirror_point = get_distance_rbf(svm, query_point)\n",
                "\n",
                "print(f\"Query point: {query_point}, Distance: {svm.decision_function([query_point])}\")\n",
                "print(f\"Mirror point: {mirror_point}, Distance: {svm.decision_function([mirror_point])}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "P58vL9l-HzOg"
            },
            "source": [
                "##### Method 3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "k1zjwQxYHzOh",
                "outputId": "90ee7d90-abac-43cd-fc42-dc452f3da68e"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "def rbf_kernel(x, y, gamma):\n",
                "    return np.exp(-gamma * np.linalg.norm(x - y) ** 2)\n",
                "\n",
                "def distance_to_hyperplane(clf, x_i):\n",
                "    # Get support vectors and dual coefficients\n",
                "    support_vectors = clf.support_vectors_\n",
                "    dual_coefficients = clf.dual_coef_.ravel()\n",
                "    gamma = clf._gamma\n",
                "\n",
                "    # Compute the decision function value\n",
                "    decision_function_value = 0\n",
                "    for i in range(len(support_vectors)):\n",
                "        decision_function_value += dual_coefficients[i] * rbf_kernel(support_vectors[i], x_i, gamma)\n",
                "\n",
                "    decision_function_value += clf.intercept_\n",
                "\n",
                "    # Compute the distance\n",
                "    norm_w = np.linalg.norm(clf.dual_coef_ @ support_vectors)\n",
                "    distance = decision_function_value / norm_w\n",
                "    return distance\n",
                "\n",
                "X_train = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n",
                "y_train = np.array([0, 0, 1, 1])\n",
                "x_i = [-1,1]\n",
                "\n",
                "gamma = 0.1\n",
                "clf = SVC(kernel='rbf', gamma=gamma)\n",
                "clf.fit(X_train, y_train)\n",
                "\n",
                "distance_to_x_i = distance_to_hyperplane(clf, x_i)\n",
                "distance_to_x_i, clf.decision_function([x_i])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "xobI4RCaHzOh"
            },
            "source": [
                "### RBF Kernel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "referenced_widgets": [
                        "79a306f1966c4dc4bd12a14f802fbe03"
                    ]
                },
                "id": "t0x3ISf4HzOh",
                "outputId": "ef70837b-ffa5-49af-fcdf-3d74edf5f67b"
            },
            "outputs": [],
            "source": [
                "def split_matrix(mat, max_sz):\n",
                "    num_rows = mat.shape[0]\n",
                "    num_splits = (num_rows - 1) // max_sz + 1\n",
                "    split_matrices = []\n",
                "\n",
                "    for i in range(num_splits):\n",
                "        start_idx = i * max_sz\n",
                "        end_idx = min((i + 1) * max_sz, num_rows)\n",
                "        split_matrices.append(mat[start_idx:end_idx])\n",
                "\n",
                "    return tuple(split_matrices)\n",
                "\n",
                "def calc_dif_norms(l_mat, s_mat, axis=1, max_sz=1000, show_prog=False):\n",
                "    mat_tup = split_matrix(l_mat, max_sz)\n",
                "    norms = []\n",
                "\n",
                "    if show_prog: print(\"Calculating norms...\")\n",
                "    for m in tqdm(mat_tup, disable=not show_prog):\n",
                "        n_m = np.expand_dims(m, axis=1)\n",
                "        norm_batch = np.linalg.norm(n_m-s_mat, axis=1)\n",
                "        norms.extend(norm_batch)\n",
                "    norms = np.array(norms)\n",
                "    return norms\n",
                "\n",
                "def rbf(x, model):\n",
                "    gamma = model._gamma\n",
                "    svs = model.support_vectors_.toarray()\n",
                "    norms = calc_dif_norms(svs, x, show_prog=True)\n",
                "    k = np.exp(-gamma*norms)\n",
                "    return k\n",
                "\n",
                "\n",
                "k = rbf(x[:2], svc_rbf)\n",
                "k.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Final Implementation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Counterfactual Generator: T5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.analyzers import SVMAnalyzer\n",
                "analyzer = SVMAnalyzer(\n",
                "    svm_path=\"./models/analysis-models/svm.pkl\",\n",
                "    vectorizer_path=\"./models/analysis-models/tfidf.pkl\",\n",
                "    cf_generator_config_path=\"./configs/models/t5-cf-generator.yaml\",\n",
                "    cf_generator_root=\"./models/cf-generator\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "review = \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me. The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
                "search_space = 2\n",
                "cf = analyzer(review, search_space)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "explanation = analyzer.explanation()\n",
                "print(explanation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Counterfactual Generator: WordFlipping"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Predefined configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.analyzers import SVMAnalyzer\n",
                "analyzer = SVMAnalyzer(\n",
                "    svm_path=\"./models/analysis-models/svm.pkl\",\n",
                "    vectorizer_path=\"./models/analysis-models/tfidf.pkl\",\n",
                "    cf_generator_config=\"./configs/models/wf-cf-generator.yaml\"\n",
                ")\n",
                "review = \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me. The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
                "search_space = 2\n",
                "cf = analyzer(review, search_space)\n",
                "explanation = analyzer.explanation()\n",
                "print(explanation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Test bench"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.test_bench import TestBench\n",
                "\n",
                "configurations = [\n",
                "    {\n",
                "        \"name\": \"adjectives\",\n",
                "        \"generator_config\": {\n",
                "            \"sample_prob_decay_factor\": 0.2,\n",
                "            \"flip_prob\": 0.5,\n",
                "            \"flipping_tags\": [\"JJ\", \"JJR\", \"JJS\"],\n",
                "        },\n",
                "    },\n",
                "    {\n",
                "        \"name\": \"nouns\",\n",
                "        \"generator_config\": {\n",
                "            \"sample_prob_decay_factor\": 0.2,\n",
                "            \"flip_prob\": 0.5,\n",
                "            \"flipping_tags\": [\"NN\", \"NNP\", \"NNPS\", \"NNS\"],\n",
                "        },\n",
                "    },\n",
                "    {\n",
                "        \"name\": \"adverbs\",\n",
                "        \"generator_config\": {\n",
                "            \"sample_prob_decay_factor\": 0.2,\n",
                "            \"flip_prob\": 0.5,\n",
                "            \"flipping_tags\": [\"RB\", \"RBR\", \"RBS\", \"RP\"],\n",
                "        },\n",
                "    },\n",
                "    {\n",
                "        \"name\": \"verbs\",\n",
                "        \"generator_config\": {\n",
                "            \"sample_prob_decay_factor\": 0.2,\n",
                "            \"flip_prob\": 0.5,\n",
                "            \"flipping_tags\": [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"],\n",
                "        },\n",
                "    },\n",
                "]\n",
                "text=\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
                "\n",
                "tb = TestBench(\n",
                "    model_path=\"./models/analysis-models/svm.pkl\",\n",
                "    vectorizer_path=\"./models/analysis-models/tfidf.pkl\",\n",
                "    analyzer_name=\"svm\",\n",
                "    cf_generator_config=\"./configs/models/wf-cf-generator.yaml\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reports = tb(configurations, text, 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for report in reports:\n",
                "    print(report)\n",
                "    print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.datasets import IMDBDataset\n",
                "\n",
                "ds = IMDBDataset(config_path=\"./configs/datasets/imdb.yaml\", root=\"datasets/imdb\")\n",
                "tb.evaluate(ds.x_test, ds.y_test, save_dir=\"evaluations/svm\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [
                "UyNc81DoHzOU"
            ],
            "provenance": []
        },
        "kernelspec": {
            "display_name": "xai",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.17"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
